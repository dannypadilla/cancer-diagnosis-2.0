{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "\n",
    "### TODO:\n",
    " * part H - plot ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer Diagnosis Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __a. Read the dataset file “Cancer.csv” (you should download it from CSNS), and store it in a Pandas DataFrame.__\n",
    "\n",
    "* Check out the dataset.\n",
    "\n",
    "* The dataset includes 9 numerical features.\n",
    "\n",
    "* The last column is the binary label (“1” means it is a malignant cancer, “0” means it is a benign tumor).\n",
    "\n",
    "* You will use all 9 features in this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"HW1/Cancer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"Clump_Thickness\",\n",
    "    \"Uniformity_of_Cell_Size\",\n",
    "    \"Uniformity_of_Cell_Shape\",\n",
    "    \"Marginal_Adhesion\",\n",
    "    \"Single_Epithelial_Cell_Size\",\n",
    "    \"Bare_Nuclei\",\n",
    "    \"Bland_Chromatin\",\n",
    "    \"Normal_Nucleoli\",\n",
    "    \"Mitoses\"\n",
    "]\n",
    "\n",
    "X = data[feature_names]\n",
    "\n",
    "y = data[\"Malignant_Cancer\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*display features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "0                  1                            2            1   \n",
       "1                  5                            7           10   \n",
       "2                  1                            2            2   \n",
       "3                  1                            3            4   \n",
       "4                  3                            2            1   \n",
       "\n",
       "   Bland_Chromatin  Normal_Nucleoli  Mitoses  \n",
       "0                3                1        1  \n",
       "1                3                2        1  \n",
       "2                3                1        1  \n",
       "3                3                7        1  \n",
       "4                3                1        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*display labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Malignant_Cancer, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __b. Use sklearn functions to split the dataset into testing and training sets with the following parameters:__\n",
    "\n",
    "```test_size=0.3, random_state=2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __c. Use “Decision Tree Classifier” to predict Cancer based on the training/testing datasets that you built in part (b).__\n",
    "\n",
    "* Then, calculate and report the accuracy and AUC of your classifier.\n",
    "\n",
    "* Later in __part (g)__, you will plot the `ROC curve` as well. Use this command to define your tree:\n",
    "\n",
    "  ```my_DecisionTree = DecisionTreeClassifier(random_state=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_DecisionTree = DecisionTreeClassifier(random_state = 2)\n",
    "my_DecisionTree.fit(X_train, y_train)\n",
    "dt_prediction = my_DecisionTree.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*show decision tree accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree AUC: 0.8697478991596639\n"
     ]
    }
   ],
   "source": [
    "dt_false_pr, dt_true_pr, dt_thresholds = metrics.roc_curve(y_test, dt_prediction, pos_label = 1)\n",
    "\n",
    "dt_AUC = metrics.auc(dt_false_pr, dt_true_pr)\n",
    "\n",
    "print(\"Decision Tree AUC:\", dt_AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __d. Now, we want to perform “Bagging” based on 29 “base decision tree classifiers”.__\n",
    "\n",
    "---\n",
    "\n",
    "  __NOTE:__\n",
    "\n",
    "    You should write your own code to perform Bagging (don’t use scikit-learn functions for Bagging!)\n",
    "    \n",
    "---\n",
    "    \n",
    "  To do so, you need to perform bootstrapping first. You can write a “for” loop with loop variable `i = 0...18`.\n",
    "  \n",
    "  __In each iteration of the loop, you have to:__\n",
    "  \n",
    "  \n",
    "  - Make a bootstrap sample of the original “Training” Dataset (built in __part (b)__ ) with size of:\n",
    "  \n",
    "      `bootstrap_size = 0.8*(Size of the original dataset)`.\n",
    "  \n",
    "  You can use the following command to generate a random bootstrap dataset (“i\" is the variable of the loop, so the random_state changes in each iteration):\n",
    "  \n",
    "  ```resample(X_train, n_samples = bootstrap_size , random_state=i , replace = True)```\n",
    "  \n",
    "  \n",
    "  - Define and train a new base decision tree classifier on this dataset in each iteration:\n",
    "    \n",
    "    ```Base_DecisionTree = DecisionTreeClassifier(random_state=2)```\n",
    "  \n",
    "  \n",
    "  - Test “this base classifier” on the original “Testing” Dataset build in __part (b)__, and save the prediction results for all testing samples.\n",
    "  \n",
    "Then, Perform Voting to make the final decision on each data sample based on the votes of all 29 classifiers.\n",
    "\n",
    "Finally, calculate and report the accuracy and AUC of your Bagging method.\n",
    "\n",
    "---\n",
    "\n",
    "  __NOTE:__\n",
    "  \n",
    "    You need to calculate the probability of “malignant cancer” to be able to find AUC and plot the ROC curve. As mentioned in the class, you can consider the average (mean) of the votes as the probability for each sample.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booststrap size: 84\n"
     ]
    }
   ],
   "source": [
    "base_decision_tree_classifiers = 29\n",
    "\n",
    "size_of_original_dataset = X_train.shape[0]\n",
    "\n",
    "bootstrap_size = int(0.8 * size_of_original_dataset)\n",
    "print(\"Booststrap size:\", bootstrap_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*bootstrapping*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = pd.DataFrame()\n",
    "\n",
    "for i in range(base_decision_tree_classifiers):\n",
    "    X_train_i = resample(X_train, n_samples = bootstrap_size, random_state = i, replace = True)\n",
    "    y_train_i = resample(y_train, n_samples = bootstrap_size, random_state = i, replace = True)\n",
    "    \n",
    "    Base_DecisionTree = DecisionTreeClassifier(random_state = 2)\n",
    "    Base_DecisionTree.fit(X_train_i, y_train_i)\n",
    "    \n",
    "    y_predict_bdt = Base_DecisionTree.predict(X_test)\n",
    "    \n",
    "    prediction_list[i] = y_predict_bdt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*voting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Votes: 45\n"
     ]
    }
   ],
   "source": [
    "voting = prediction_list.mode(axis = 1)\n",
    "print(\"Number of Votes:\", voting.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "score_ab = accuracy_score(y_test, voting)\n",
    "print(\"Bagging Accuracy:\", score_ab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging AUC: 0.9054621848739496\n"
     ]
    }
   ],
   "source": [
    "bag_false_pr, bag_true_pr, bag_thresholds = metrics.roc_curve(y_test, voting, pos_label = 1)\n",
    "\n",
    "bag_AUC = metrics.auc(bag_false_pr, bag_true_pr)\n",
    "\n",
    "print(\"Bagging AUC:\", bag_AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __e. Use scikit-learn “Adaboost” classifier to predict Cancer based on the training/testing datasets that you built in part (b).__\n",
    "\n",
    "* Then, calculate and report the accuracy and AUC of your classifier. Use this command to import and define your classifier:\n",
    "\n",
    "    ```from sklearn.ensemble import AdaBoostClassifier```\n",
    "    \n",
    "    ``` my_AdaBoost = AdaBoostClassifier(n_estimators = 29,random_state=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_AdaBoost = AdaBoostClassifier(n_estimators = 29, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_AdaBoost.fit(X_train, y_train)\n",
    "ada_prediction = my_AdaBoost.predict(X_test)\n",
    "ada_accuracy = accuracy_score(y_test, ada_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost Accuracy:\", ada_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost AUC: 0.9527310924369748\n"
     ]
    }
   ],
   "source": [
    "ada_false_pr, ada_true_pr, ada_thresholds = metrics.roc_curve(y_test, ada_prediction, pos_label = 1)\n",
    "\n",
    "ada_AUC = metrics.auc(ada_false_pr, ada_true_pr)\n",
    "\n",
    "print(\"AdaBoost AUC:\", ada_AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __f. In this section, we use an extremely popular Boosting algorithm called “XGBoost”.__\n",
    "  This algorithm is not included in sklearn, so you need to install the XGBoost library.\n",
    "  \n",
    "  Please see this for more info: https://xgboost.readthedocs.io/en/latest/build.html\n",
    "  \n",
    "  Mac users can easily install it with “`pip install xgboost`”.\n",
    "\n",
    "* Repeat __part (e)__ with XGBoost.\n",
    "\n",
    "  - Use this command to import and define your classifier:\n",
    "  \n",
    "    ```from xgboost import XGBClassifier```\n",
    "  \n",
    "    ```my_XGBoost = XGBClassifier(n_estimators = 29,random_state=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_XGBoost = xgb.XGBClassifier(n_estimators = 29, n_jobs = -1, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtrain = xgb.DMatrix(X_train, label = y_train, feature_names = feature_names, nthread=-1) # no need to convert\n",
    "#my_XGBoost.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "my_XGBoost.fit(X_train, y_train)\n",
    "\n",
    "xgb_prediction = my_XGBoost.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Accuracy:\", xgb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUC: 0.9527310924369748\n"
     ]
    }
   ],
   "source": [
    "xgb_false_pr, xgb_true_pr, xgb_thresholds = metrics.roc_curve(y_test, xgb_prediction, pos_label = 1)\n",
    "\n",
    "xgb_AUC = metrics.auc(xgb_false_pr, xgb_true_pr)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __g. Use scikit-learn “Random Forest” classifier to predict Cancer based on the training/testing datasets that you built in part (b).__\n",
    "\n",
    "* Then, calculate and report the accuracy and AUC of your classifier.\n",
    "  - Use this command to import and define your classifier:\n",
    "  \n",
    "    ```from sklearn.ensemble import RandomForestClassifier```\n",
    "  \n",
    "    ```my_RandomForest = RandomForestClassifier(n_estimators = 29, bootstrap = True, random_state=2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_RandomForest = RandomForestClassifier(n_estimators = 29, bootstrap = True, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_RandomForest.fit(X_train, y_train)\n",
    "rf_prediction = my_RandomForest.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "rf_false_pr, rf_true_pr, rf_thresholds = metrics.roc_curve(y_test, rf_prediction, pos_label = 1)\n",
    "\n",
    "rf_AUC = metrics.auc(rf_false_pr, rf_true_pr)\n",
    "\n",
    "print(\"Random Forest AUC:\", rf_AUC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __h. Now, plot the ROC curves of your algorithms in parts (c), (d), (e), (f), (g) in a single plane with different colors along with the name of each method.__\n",
    "\n",
    "    Show the AUCs on the graph as well.\n",
    "    \n",
    "    - Which algorithm is the best w.r.t the AUC value?\n",
    "    \n",
    "    - Which algorithm is the best w.r.t the Accuracy value?\n",
    "    \n",
    "    - Which algorithm is the best when we want a False Positive Rate of 7%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
